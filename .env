# Model Provider Configuration
MODEL_PROVIDER=huggingface

# HuggingFace Configuration (Active)
HF_MODEL_NAME=sentence-transformers/all-mpnet-base-v2
HF_TEMPERATURE=0.3
HF_MAX_LENGTH=1000
HF_DEVICE=auto

# HuggingFace API Configuration (Optional - for faster inference)
# Set HF_USE_API=true to use HuggingFace Inference API instead of local models
HF_USE_API=false
HF_API_TOKEN=yhf_vbzcKUYnEnShnPmQgoJxOBkoXOaTKjChAU
HF_API_URL=https://api-inference.huggingface.co/models/

# OpenAI Configuration (Commented out)
# OPENAI_API_KEY=your_openai_api_key_here
# OPENAI_MODEL=gpt-3.5-turbo
# OPENAI_TEMPERATURE=0.3
# OPENAI_MAX_TOKENS=1500

# Application Configuration
STREAMLIT_SERVER_PORT=8501
STREAMLIT_SERVER_ADDRESS=localhost